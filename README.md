# **Semantic Caching for Generative AI**
ğŸš€ **A Python package for caching AI-generated responses using Redis and FAISS for semantic similarity search.**  
Designed to **reduce computation time, improve response speed, and enable cross-session caching** for AI models.

---

## ğŸŒŸ **Features**
âœ… **Cross-session & Cross-user Caching** â€“ Combines an in-memory cache (session) with a persistent Redis-based cache.  
âœ… **Semantic Similarity Search** â€“ Uses **FAISS** to find semantically similar cached responses.  
âœ… **Efficient Cache Management** â€“ Supports LRU eviction, cache expiration policies, and manual invalidation.  
âœ… **Configurable Storage Policies** â€“ Define TTL, eviction policies, and dynamic cache limits.  
âœ… **Robust & Production-Ready** â€“ Includes logging, monitoring, and optimized error handling.

---

## ğŸ“¦ **Folder Structure**
```
semantic_cache/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ cache_manager.py       # Manages cache retrieval, similarity search, and storage policies
â”œâ”€â”€ config.py              # Stores configurable settings (Redis, FAISS, cache policies)
â”œâ”€â”€ embedding.py           # Generates embeddings using SentenceTransformers
â”œâ”€â”€ persistent_cache.py    # Redis-based persistent caching implementation
â”œâ”€â”€ session_cache.py       # Thread-safe in-memory session cache
â”œâ”€â”€ utils.py               # Utility functions (logging setup, error handling)
â”œâ”€â”€ vector_store.py        # FAISS-based vector store for similarity search
tests/                     # Unit tests for each module
â”œâ”€â”€ test_cache_manager.py
â”œâ”€â”€ test_embedding.py
â”œâ”€â”€ test_persistent_cache.py
â”œâ”€â”€ test_session_cache.py
â”œâ”€â”€ test_vector_store.py
setup.py                   # Setup script for packaging
environment.yml             # Conda environment configuration
README.md                  # Project documentation
```

---

## ğŸ› ï¸ **Installation**
### **1ï¸âƒ£ Setup Conda Environment**
```sh
conda env create --file environment.yml
conda activate semantic_cache_env
```

### **2ï¸âƒ£ Install the Package**
```sh
pip install -e .
```

### **3ï¸âƒ£ Install Redis Locally (If Needed)**
```sh
# Ubuntu / Debian
sudo apt update && sudo apt install redis-server

# MacOS (Homebrew)
brew install redis
brew services start redis

# Docker (Alternative)
docker run --name redis -p 6379:6379 -d redis
```

---

## ğŸš€ **Usage**
### **1ï¸âƒ£ Basic Example**
```python
from semantic_cache.cache_manager import CacheManager
from semantic_cache.persistent_cache import PersistentCache
from semantic_cache.session_cache import SessionCache
from semantic_cache.vector_store import VectorStore

# Initialize caches and vector store
persistent_cache = PersistentCache()
session_cache = SessionCache()
vector_store = VectorStore(dim=768)
cache_manager = CacheManager(persistent_cache, session_cache, vector_store)

# Example query
query = "What is the weather today?"
response = "It's sunny and 25Â°C."

# Store in cache
cache_manager.set(query, response)

# Retrieve cached response
cached_response = cache_manager.get(query)
print(cached_response)  # Output: "It's sunny and 25Â°C."
```

---

## ğŸ” **How It Works**
### **Cache Lookup Order**
1ï¸âƒ£ **Session Cache (Fastest)** â†’ Checks if query exists in memory.  
2ï¸âƒ£ **Persistent Redis Cache** â†’ If not in memory, checks Redis.  
3ï¸âƒ£ **Semantic Search via FAISS** â†’ If not in Redis, searches for semantically similar queries.  
4ï¸âƒ£ **Cache Miss â†’ Generate Response** â†’ If no match, call the AI model and store the response.  

---

## ğŸ§ª **Running Tests**
```sh
pytest tests/
```

---

## ğŸ— **Planned Enhancements (Next Version)**
### âœ… **1ï¸âƒ£ Improved Embedding Module**
- [ ] Support multiple embedding models (OpenAI, Hugging Face, Custom LLMs).
- [ ] Dynamic embedding selection based on use case.

### âœ… **2ï¸âƒ£ Advanced Cache Policies**
- [ ] Implement **dynamic TTLs** based on query frequency.
- [ ] **Pre-warm** the cache with commonly used queries.
- [ ] Support **cache sharding** for large-scale applications.

### âœ… **3ï¸âƒ£ FAISS Enhancements**
- [ ] **Better handling of deletions** (re-indexing strategy).
- [ ] Support **multi-threaded FAISS searches** for faster lookups.
- [ ] Use **quantization** for memory-efficient FAISS storage.

### âœ… **4ï¸âƒ£ Redis Improvements**
- [ ] Support **Redis Clustering** for distributed caching.
- [ ] Implement **auto-reconnect & failover** for Redis failures.
- [ ] Add **backup mechanisms** for persisted cache storage.

### âœ… **5ï¸âƒ£ Production Optimization**
- [ ] Integrate **Prometheus/Grafana for monitoring** cache performance.
- [ ] Implement **async caching** using Celery or background workers.
- [ ] Provide **REST API endpoints** for caching operations.

### âœ… **6ï¸âƒ£ Better Developer Experience**
- [ ] **Add detailed logging** for debugging cache operations.
- [ ] **Create CLI tool** to inspect & manage the cache.
- [ ] **Auto-generate API documentation** using Sphinx or MkDocs.

---

## ğŸ† **Contributing**
ğŸ™Œ Contributions are welcome! To contribute:
1. **Fork** the repository.
2. **Create** a feature branch (`git checkout -b feature-new-enhancement`).
3. **Commit** your changes (`git commit -m "Added new feature"`).
4. **Push** and **open a pull request**.

---

## ğŸ›¡ **License**
This project is licensed under the **MIT License**. See `LICENSE` for details.

---

## â­ **Support the Project**
If you find this project useful, please â­ **star this repository** and share your feedback! ğŸš€âœ¨

---

## ğŸ”— **Resources**
- **FAISS Documentation**: [https://faiss.ai/](https://faiss.ai/)
- **Redis Documentation**: [https://redis.io/](https://redis.io/)
- **SentenceTransformers**: [https://www.sbert.net/](https://www.sbert.net/)

---

This **README** makes it **easy to understand the package**, install and use it, and **provides a clear roadmap** for the next version. ğŸš€